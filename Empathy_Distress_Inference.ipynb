{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da3c678",
   "metadata": {},
   "source": [
    "# Inference with EmotionStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "917ac4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelWithHeads\n",
    "import torch\n",
    "from utils import utils\n",
    "from transformers import RobertaTokenizer\n",
    "import transformers.adapters.composition as ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b200e9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" load data \"\"\"\n",
    "\n",
    "train_data, val_data, test_data = utils.load_wassa_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84657b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/home/alahnala/miniconda3/envs/st/lib/python3.9/site-packages/transformers/adapters/models/roberta.py:250: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/app/home/alahnala/miniconda3/envs/st/lib/python3.9/site-packages/transformers/adapters/models/roberta.py:228: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels=1\n",
    ")\n",
    "\n",
    "model = AutoModelWithHeads.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58cb4631",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" load adapters \"\"\"\n",
    "empathy_adapter_path = \"./trained_adapters/EMP_emotion_stack\"\n",
    "distress_adapter_path = \"./trained_adapters/DIS_emotion_stack\"\n",
    "\n",
    "empathy_adapter = model.load_adapter(empathy_adapter_path, load_as=empathy_adapter_path.split('/')[-1])\n",
    "distress_adapter = model.load_adapter(distress_adapter_path, load_as=distress_adapter_path.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd72d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" activate \"\"\"\n",
    "model.set_active_adapters(ac.Parallel(empathy_adapter, distress_adapter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "598c78ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EMP_emotion_stack', 'DIS_emotion_stack']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.active_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99207840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_empathy_distress(sentence):\n",
    "    model.set_active_adapters(ac.Parallel(empathy_adapter, distress_adapter))\n",
    "    model.active_head = ['EMP_emotion_stack', 'DIS_emotion_stack']\n",
    "    \n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    input_ids = torch.tensor(tokenizer.convert_tokens_to_ids(tokens))\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "    emp = outputs[0].logits[0][0].tolist()\n",
    "    dis = outputs[1].logits[0][0].tolist()\n",
    "    return emp, dis\n",
    "\n",
    "\n",
    "def predict_and_print(sentence):\n",
    "    empathy_score, distress_score = pred_empathy_distress(sentence)\n",
    "    \n",
    "    print(\"Essay: \")\n",
    "    print(sentence)\n",
    "    print(f\"Empathy: {empathy_score}\\tDistress: {distress_score}\")\n",
    "    \n",
    "    return empathy_score, distress_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc257672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay: \n",
      "I think that this is pretty sad.  I definitely think that there should be a lot more empathy for these people.  Say what you will, but to me it's just another example of the haves keeping the have nots as far down as possible.  I wonder how this article makes you feel and I am really curious to hear your opinions on the matter.\n",
      "Empathy: 4.637167453765869\tDistress: 3.3121418952941895\n",
      "\n",
      "Actuals\n",
      "Empathy: 6.0\tDistress: 1.0\n"
     ]
    }
   ],
   "source": [
    "idx = 50\n",
    "\n",
    "essay = val_data['essay'].values[idx]\n",
    "empathy_score, distress_score = predict_and_print(essay)\n",
    "\n",
    "print(f\"\\nActuals\\nEmpathy: {val_data['empathy'].values[idx]}\\tDistress: {val_data['distress'].values[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4549bad5",
   "metadata": {},
   "source": [
    "# Inference with Epitome Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8229b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" load pretrained adapter composition \"\"\"\n",
    "\n",
    "from transformers.adapters.composition import Fuse\n",
    "\n",
    "\n",
    "fusion_path = f\"./trained_adapters/EpitomeFusion-distress\"\n",
    "\n",
    "# load each individual adapter\n",
    "dis_er_adapter = model.load_adapter(\n",
    "                fusion_path + '/distress-emotional-reactions')\n",
    "dis_ex_adapter = model.load_adapter(\n",
    "                fusion_path + '/distress-explorations')\n",
    "dis_ip_adapter = model.load_adapter(\n",
    "                fusion_path + '/distress-interpretations')\n",
    "\n",
    "# load adapter fusion\n",
    "model.load_adapter_fusion(\n",
    "    fusion_path\n",
    ")\n",
    "\n",
    "# set active adapters\n",
    "model.set_active_adapters(Fuse(dis_er_adapter, dis_ex_adapter, dis_ip_adapter))\n",
    "\n",
    "# # load head\n",
    "# path, distress_adapter = model.load_head(fusion_path)\n",
    "\n",
    "model.active_head = 'EpitomeFusion-distress'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00f8398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" load pretrained adapter composition: empathy \"\"\"\n",
    "\n",
    "fusion_path = f\"./trained_adapters/EpitomeFusion-empathy\"\n",
    "\n",
    "# load each individual adapter\n",
    "emp_er_adapter = model.load_adapter(\n",
    "                fusion_path + '/empathy-emotional-reactions'\n",
    "            )\n",
    "emp_ex_adapter = model.load_adapter(\n",
    "                fusion_path + '/empathy-explorations'\n",
    "            )\n",
    "emp_ip_adapter = model.load_adapter(\n",
    "                fusion_path + '/empathy-interpretations'\n",
    "            )\n",
    "\n",
    "# load adapter fusion\n",
    "model.load_adapter_fusion(\n",
    "    fusion_path\n",
    ")\n",
    "\n",
    "# set active adapters\n",
    "model.set_active_adapters(Fuse(emp_er_adapter, emp_ex_adapter, emp_ip_adapter))\n",
    "\n",
    "# # load head\n",
    "# path, empathy_adapter = model.load_head(fusion_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7a6e793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EpitomeFusion-empathy'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.active_head = 'EpitomeFusion-empathy'\n",
    "model.active_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dba29978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fusion(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    input_ids = torch.tensor(tokenizer.convert_tokens_to_ids(tokens))\n",
    "    \n",
    "    # set active adapters\n",
    "    model.set_active_adapters(Fuse(dis_er_adapter, dis_ex_adapter, dis_ip_adapter))\n",
    "    model.active_head = 'EpitomeFusion-distress'\n",
    "    outputs = model(input_ids)\n",
    "    distress_score = outputs.logits[0][0].tolist()\n",
    "    \n",
    "    # set active adapters\n",
    "    model.set_active_adapters(Fuse(emp_er_adapter, emp_ex_adapter, emp_ip_adapter))\n",
    "    model.active_head = 'EpitomeFusion-empathy'\n",
    "    outputs = model(input_ids)\n",
    "    empathy_score = outputs.logits[0][0].tolist()\n",
    "    \n",
    "    return empathy_score, distress_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1545330e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted\n",
      "Empathy: 4.4249701499938965\tDistress: 3.2860703468322754\n",
      "\n",
      "Actuals\n",
      "Empathy: 6.0\tDistress: 1.0\n"
     ]
    }
   ],
   "source": [
    "idx = 50\n",
    "\n",
    "essay = val_data['essay'].values[idx]\n",
    "empathy_score, distress_score = predict_fusion(essay)\n",
    "\n",
    "print(f\"\\nPredicted\\nEmpathy: {empathy_score}\\tDistress: {distress_score}\")\n",
    "print(f\"\\nActuals\\nEmpathy: {val_data['empathy'].values[idx]}\\tDistress: {val_data['distress'].values[idx]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
