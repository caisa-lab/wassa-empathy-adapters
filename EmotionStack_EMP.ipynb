{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00a958cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import utils\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "import numpy as np\n",
    "from transformers.trainer_utils import set_seed\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import AutoConfig, AutoModelWithHeads\n",
    "from transformers.adapters.composition import Stack\n",
    "from transformers import TrainingArguments, EvalPrediction, AdapterTrainer\n",
    "from utils.evaluation import compute_pearsonr\n",
    "\n",
    "\n",
    "dateTimeObj = datetime.now()\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "set_seed(RANDOM_SEED)\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca93bf",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ba95ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" load data \"\"\"\n",
    "\n",
    "train_data, val_data, test_data = utils.load_wassa_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c213ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" get task labels \"\"\"\n",
    "\n",
    "prediction_task = 'empathy'\n",
    "\n",
    "train_labels = list(train_data[prediction_task].values)\n",
    "val_labels = list(val_data[prediction_task].values)\n",
    "test_labels = list(test_data[prediction_task].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55d6a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Prepare dataset for training: feature encodings \"\"\"\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "train_encodings = tokenizer(list(train_data['essay'].values), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(list(val_data['essay'].values), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(test_data['essay'].values), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dfe14e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" setup torch dataset \"\"\"\n",
    "\n",
    "class WassaDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = WassaDataset(train_encodings, train_labels)\n",
    "val_dataset = WassaDataset(val_encodings, val_labels)\n",
    "test_dataset = WassaDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7e85f0",
   "metadata": {},
   "source": [
    "# Stacking Emotion Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "263aafb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/home/alahnala/miniconda3/envs/st/lib/python3.9/site-packages/transformers/adapters/models/roberta.py:250: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/app/home/alahnala/miniconda3/envs/st/lib/python3.9/site-packages/transformers/adapters/models/roberta.py:228: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" init model \"\"\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels=1,\n",
    "    hidden_dropout_prob=.01,\n",
    ")\n",
    "model = AutoModelWithHeads.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da9aa98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" load emotion adapter, using: https://huggingface.co/AdapterHub/roberta-base-pf-emotion \"\"\"\n",
    "\n",
    "emotion_adapter = model.load_adapter('AdapterHub/roberta-base-pf-emotion', source=\"hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "966bb7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" add adapter for emotion prediction task \"\"\"\n",
    "\n",
    "adapter_name = \"EMP_emotion_stack\" if prediction_task == 'empathy' else 'DIS_emotion_stack'\n",
    "\n",
    "model.add_adapter(adapter_name)\n",
    "model.add_classification_head(adapter_name, num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c663e3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" activate adapter stack \"\"\"\n",
    "\n",
    "model.active_adapters = Stack(emotion_adapter, adapter_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "252d330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" activate adapter for training \"\"\"\n",
    "\n",
    "model.train_adapter([adapter_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a4a4f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "\"\"\" training arguments \"\"\"\n",
    "\n",
    "approach = 'emotion-stack'\n",
    "training_output_dir = f\"./training_output/{approach}/{prediction_task}_{dateTimeObj.hour}{dateTimeObj.minute}-{dateTimeObj.day}-{dateTimeObj.month}\"\n",
    "num_train_epochs=20\n",
    "per_device_train_batch_size=8\n",
    "per_device_eval_batch_size=8\n",
    "metric_for_best_model='eval_pearsonr'\n",
    "warmup_steps=1000\n",
    "weight_decay=0.1\n",
    "learning_rate=1e-04\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    seed=RANDOM_SEED,\n",
    "    output_dir=training_output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "     warmup_steps=warmup_steps,\n",
    "     weight_decay=weight_decay,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    eval_steps=50,\n",
    "    save_steps=50,\n",
    "    evaluation_strategy='steps',\n",
    "    disable_tqdm=False,\n",
    "    overwrite_output_dir=True,\n",
    "    remove_unused_columns=False,\n",
    "    save_strategy='steps',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_for_best_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5f3a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" setup trainer \"\"\"\n",
    "\n",
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_pearsonr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41e212f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/home/alahnala/miniconda3/envs/st/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1860\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4660\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4660' max='4660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4660/4660 03:46, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearsonr</th>\n",
       "      <th>Pearsonr Scipy</th>\n",
       "      <th>Pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>19.309900</td>\n",
       "      <td>16.890991</td>\n",
       "      <td>0.032400</td>\n",
       "      <td>0.032386</td>\n",
       "      <td>0.596227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>16.915300</td>\n",
       "      <td>14.795216</td>\n",
       "      <td>-0.025300</td>\n",
       "      <td>-0.025309</td>\n",
       "      <td>0.678867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>12.537700</td>\n",
       "      <td>9.282456</td>\n",
       "      <td>-0.046500</td>\n",
       "      <td>-0.046473</td>\n",
       "      <td>0.446959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.498100</td>\n",
       "      <td>3.572055</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.041799</td>\n",
       "      <td>0.494016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.822200</td>\n",
       "      <td>3.515375</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.128594</td>\n",
       "      <td>0.034688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.415000</td>\n",
       "      <td>3.281997</td>\n",
       "      <td>0.232700</td>\n",
       "      <td>0.232664</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.996200</td>\n",
       "      <td>3.309586</td>\n",
       "      <td>0.288500</td>\n",
       "      <td>0.288478</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.115500</td>\n",
       "      <td>3.248243</td>\n",
       "      <td>0.366900</td>\n",
       "      <td>0.366937</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.901800</td>\n",
       "      <td>2.992455</td>\n",
       "      <td>0.402500</td>\n",
       "      <td>0.402491</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.018400</td>\n",
       "      <td>2.980379</td>\n",
       "      <td>0.405900</td>\n",
       "      <td>0.405915</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.828000</td>\n",
       "      <td>2.881994</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>0.441549</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.752300</td>\n",
       "      <td>3.026447</td>\n",
       "      <td>0.440800</td>\n",
       "      <td>0.440811</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.887500</td>\n",
       "      <td>3.267769</td>\n",
       "      <td>0.433600</td>\n",
       "      <td>0.433560</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.348400</td>\n",
       "      <td>2.959512</td>\n",
       "      <td>0.426200</td>\n",
       "      <td>0.426161</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.693400</td>\n",
       "      <td>3.098579</td>\n",
       "      <td>0.443500</td>\n",
       "      <td>0.443452</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.596600</td>\n",
       "      <td>3.255201</td>\n",
       "      <td>0.439000</td>\n",
       "      <td>0.439037</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.782600</td>\n",
       "      <td>2.948339</td>\n",
       "      <td>0.464500</td>\n",
       "      <td>0.464453</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.644700</td>\n",
       "      <td>2.783429</td>\n",
       "      <td>0.453500</td>\n",
       "      <td>0.453462</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.695600</td>\n",
       "      <td>3.289504</td>\n",
       "      <td>0.475400</td>\n",
       "      <td>0.475422</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.613400</td>\n",
       "      <td>3.164393</td>\n",
       "      <td>0.454800</td>\n",
       "      <td>0.454752</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.407100</td>\n",
       "      <td>3.170799</td>\n",
       "      <td>0.448800</td>\n",
       "      <td>0.448765</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.665700</td>\n",
       "      <td>2.805885</td>\n",
       "      <td>0.469500</td>\n",
       "      <td>0.469452</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.485000</td>\n",
       "      <td>3.131228</td>\n",
       "      <td>0.457200</td>\n",
       "      <td>0.457162</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.293800</td>\n",
       "      <td>2.816927</td>\n",
       "      <td>0.463800</td>\n",
       "      <td>0.463848</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.442200</td>\n",
       "      <td>2.926569</td>\n",
       "      <td>0.429700</td>\n",
       "      <td>0.429709</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.255100</td>\n",
       "      <td>2.802268</td>\n",
       "      <td>0.453100</td>\n",
       "      <td>0.453136</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.657200</td>\n",
       "      <td>3.380380</td>\n",
       "      <td>0.455400</td>\n",
       "      <td>0.455416</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.072500</td>\n",
       "      <td>2.780463</td>\n",
       "      <td>0.461500</td>\n",
       "      <td>0.461526</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.440600</td>\n",
       "      <td>2.811992</td>\n",
       "      <td>0.454800</td>\n",
       "      <td>0.454838</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.093500</td>\n",
       "      <td>2.942077</td>\n",
       "      <td>0.446000</td>\n",
       "      <td>0.445995</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>2.067100</td>\n",
       "      <td>3.438705</td>\n",
       "      <td>0.436900</td>\n",
       "      <td>0.436940</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.059900</td>\n",
       "      <td>2.951493</td>\n",
       "      <td>0.453200</td>\n",
       "      <td>0.453185</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>1.961900</td>\n",
       "      <td>3.000555</td>\n",
       "      <td>0.441000</td>\n",
       "      <td>0.440987</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.859800</td>\n",
       "      <td>2.958761</td>\n",
       "      <td>0.440500</td>\n",
       "      <td>0.440501</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>1.952100</td>\n",
       "      <td>2.887219</td>\n",
       "      <td>0.435400</td>\n",
       "      <td>0.435417</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.869700</td>\n",
       "      <td>3.017752</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.443959</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>1.855500</td>\n",
       "      <td>2.985546</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.426759</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.619100</td>\n",
       "      <td>2.915619</td>\n",
       "      <td>0.449600</td>\n",
       "      <td>0.449598</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>1.897400</td>\n",
       "      <td>3.382917</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.455583</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.563200</td>\n",
       "      <td>3.107266</td>\n",
       "      <td>0.444700</td>\n",
       "      <td>0.444733</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>1.597300</td>\n",
       "      <td>3.574908</td>\n",
       "      <td>0.405900</td>\n",
       "      <td>0.405894</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.920900</td>\n",
       "      <td>3.165675</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.404052</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>1.329400</td>\n",
       "      <td>2.957984</td>\n",
       "      <td>0.431400</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.434000</td>\n",
       "      <td>3.101522</td>\n",
       "      <td>0.413400</td>\n",
       "      <td>0.413372</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>1.358800</td>\n",
       "      <td>3.507525</td>\n",
       "      <td>0.424100</td>\n",
       "      <td>0.424129</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.510500</td>\n",
       "      <td>3.519733</td>\n",
       "      <td>0.404600</td>\n",
       "      <td>0.404637</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>1.533200</td>\n",
       "      <td>3.206959</td>\n",
       "      <td>0.432300</td>\n",
       "      <td>0.432322</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.259200</td>\n",
       "      <td>3.092562</td>\n",
       "      <td>0.422100</td>\n",
       "      <td>0.422108</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>1.248300</td>\n",
       "      <td>3.298563</td>\n",
       "      <td>0.408600</td>\n",
       "      <td>0.408646</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.209400</td>\n",
       "      <td>3.269555</td>\n",
       "      <td>0.405200</td>\n",
       "      <td>0.405156</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>1.320900</td>\n",
       "      <td>3.257768</td>\n",
       "      <td>0.403100</td>\n",
       "      <td>0.403120</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.414034</td>\n",
       "      <td>0.391700</td>\n",
       "      <td>0.391672</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.991000</td>\n",
       "      <td>3.395062</td>\n",
       "      <td>0.392900</td>\n",
       "      <td>0.392863</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.022700</td>\n",
       "      <td>3.396872</td>\n",
       "      <td>0.393800</td>\n",
       "      <td>0.393788</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>3.481642</td>\n",
       "      <td>0.400800</td>\n",
       "      <td>0.400834</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.966500</td>\n",
       "      <td>3.262680</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.401392</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.781200</td>\n",
       "      <td>3.474135</td>\n",
       "      <td>0.380500</td>\n",
       "      <td>0.380527</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.858100</td>\n",
       "      <td>3.339504</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.404060</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>3.246399</td>\n",
       "      <td>0.415200</td>\n",
       "      <td>0.415247</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.827300</td>\n",
       "      <td>3.413688</td>\n",
       "      <td>0.407300</td>\n",
       "      <td>0.407295</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.776600</td>\n",
       "      <td>3.440491</td>\n",
       "      <td>0.398000</td>\n",
       "      <td>0.397957</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>3.333610</td>\n",
       "      <td>0.395700</td>\n",
       "      <td>0.395716</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.644500</td>\n",
       "      <td>3.396586</td>\n",
       "      <td>0.405500</td>\n",
       "      <td>0.405547</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.757700</td>\n",
       "      <td>3.679249</td>\n",
       "      <td>0.407600</td>\n",
       "      <td>0.407552</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.754100</td>\n",
       "      <td>3.455410</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>0.391770</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.646000</td>\n",
       "      <td>3.487763</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.402356</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.721100</td>\n",
       "      <td>3.433628</td>\n",
       "      <td>0.403300</td>\n",
       "      <td>0.403260</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.566500</td>\n",
       "      <td>3.551916</td>\n",
       "      <td>0.389700</td>\n",
       "      <td>0.389731</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.628000</td>\n",
       "      <td>3.440335</td>\n",
       "      <td>0.387900</td>\n",
       "      <td>0.387935</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.519200</td>\n",
       "      <td>3.633542</td>\n",
       "      <td>0.379100</td>\n",
       "      <td>0.379096</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.477200</td>\n",
       "      <td>3.621106</td>\n",
       "      <td>0.369300</td>\n",
       "      <td>0.369294</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.534800</td>\n",
       "      <td>3.587490</td>\n",
       "      <td>0.372200</td>\n",
       "      <td>0.372244</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.500800</td>\n",
       "      <td>3.583396</td>\n",
       "      <td>0.382800</td>\n",
       "      <td>0.382828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.508200</td>\n",
       "      <td>3.721997</td>\n",
       "      <td>0.370800</td>\n",
       "      <td>0.370848</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>3.491980</td>\n",
       "      <td>0.386200</td>\n",
       "      <td>0.386155</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.454900</td>\n",
       "      <td>3.653115</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.381651</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.494400</td>\n",
       "      <td>3.776530</td>\n",
       "      <td>0.366800</td>\n",
       "      <td>0.366830</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.497800</td>\n",
       "      <td>3.652168</td>\n",
       "      <td>0.379500</td>\n",
       "      <td>0.379539</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.400900</td>\n",
       "      <td>3.644747</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.374874</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.452700</td>\n",
       "      <td>3.633805</td>\n",
       "      <td>0.370500</td>\n",
       "      <td>0.370455</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.460900</td>\n",
       "      <td>3.669631</td>\n",
       "      <td>0.373300</td>\n",
       "      <td>0.373307</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.446400</td>\n",
       "      <td>3.709892</td>\n",
       "      <td>0.369300</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>3.718185</td>\n",
       "      <td>0.369900</td>\n",
       "      <td>0.369859</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.411500</td>\n",
       "      <td>3.635448</td>\n",
       "      <td>0.370100</td>\n",
       "      <td>0.370098</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.369800</td>\n",
       "      <td>3.617897</td>\n",
       "      <td>0.368900</td>\n",
       "      <td>0.368881</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.315200</td>\n",
       "      <td>3.666198</td>\n",
       "      <td>0.363500</td>\n",
       "      <td>0.363468</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.404200</td>\n",
       "      <td>3.673389</td>\n",
       "      <td>0.366700</td>\n",
       "      <td>0.366681</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.420400</td>\n",
       "      <td>3.760083</td>\n",
       "      <td>0.371800</td>\n",
       "      <td>0.371751</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>0.397000</td>\n",
       "      <td>3.684776</td>\n",
       "      <td>0.366200</td>\n",
       "      <td>0.366204</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.398200</td>\n",
       "      <td>3.678138</td>\n",
       "      <td>0.370400</td>\n",
       "      <td>0.370449</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>0.356700</td>\n",
       "      <td>3.682488</td>\n",
       "      <td>0.371200</td>\n",
       "      <td>0.371209</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.374600</td>\n",
       "      <td>3.686512</td>\n",
       "      <td>0.371500</td>\n",
       "      <td>0.371501</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>0.336100</td>\n",
       "      <td>3.675383</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.369965</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-50/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200/EMP_emotion_stack/head_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-350/EMP_emotion_stack/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550/EMP_emotion_stack/head_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-700/EMP_emotion_stack/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-750/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-800/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-850/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900/EMP_emotion_stack/head_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-900/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1000/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1050/EMP_emotion_stack/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250/EMP_emotion_stack/pytorch_adapter.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1350/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400/EMP_emotion_stack/head_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600/EMP_emotion_stack/adapter_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1700/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750/emotion/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1750/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1800/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1850/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1900/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950/emotion/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-1950/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2000/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2050/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100/emotion/head_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300/emotion/head_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2350/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450/EMP_emotion_stack/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650/emotion/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2700/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2750/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800/EMP_emotion_stack/head_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2800/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2850/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2900/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-2950/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000/emotion/head_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3000/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3050/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150/EMP_emotion_stack/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350/emotion/pytorch_adapter.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3350/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500/EMP_emotion_stack/head_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700/emotion/adapter_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3700/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3750/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3800/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850/EMP_emotion_stack/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3850/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3900/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-3950/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4000/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4050/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4100/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4150/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200/EMP_emotion_stack/head_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4200/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4250/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4300/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4350/EMP_emotion_stack/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4400/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4450/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4500/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550/EMP_emotion_stack/pytorch_adapter.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4550/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4600/EMP_emotion_stack/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650/emotion/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650/emotion/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650/EMP_emotion_stack/adapter_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650/emotion/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650/emotion/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650/EMP_emotion_stack/head_config.json\n",
      "Module weights saved in ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-4650/EMP_emotion_stack/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950 (score: 0.4754).\n",
      "Could not locate the best model at ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950 (score: 0.4754).\n",
      "Loading module configuration from ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/emotion/adapter_config.json\n",
      "Overwriting existing adapter 'emotion'.\n",
      "Loading module weights from ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/emotion/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/emotion/head_config.json\n",
      "Overwriting existing head 'emotion'\n",
      "Adding head 'emotion' with config {'head_type': 'classification', 'num_labels': 6, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'anger': 3, 'fear': 4, 'joy': 1, 'love': 2, 'sadness': 0, 'surprise': 5}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/emotion/pytorch_model_head.bin\n",
      "Loading module configuration from ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/EMP_emotion_stack/adapter_config.json\n",
      "Overwriting existing adapter 'EMP_emotion_stack'.\n",
      "Loading module weights from ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/EMP_emotion_stack/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/EMP_emotion_stack/head_config.json\n",
      "Overwriting existing head 'EMP_emotion_stack'\n",
      "Adding head 'EMP_emotion_stack' with config {'head_type': 'classification', 'num_labels': 1, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/emotion-stack/empathy_1921-20-4/checkpoint-950/EMP_emotion_stack/pytorch_model_head.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4660, training_loss=1.98271719723812, metrics={'train_runtime': 226.646, 'train_samples_per_second': 164.133, 'train_steps_per_second': 20.561, 'total_flos': 4371485723748000.0, 'train_loss': 1.98271719723812, 'epoch': 20.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" train \"\"\"\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c960fc71",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ede8e3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eval_loss</td>\n",
       "      <td>3.289504e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eval_pearsonr</td>\n",
       "      <td>4.754000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eval_pearsonr_scipy</td>\n",
       "      <td>4.754218e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eval_pval</td>\n",
       "      <td>1.242750e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eval_runtime</td>\n",
       "      <td>4.421000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eval_samples_per_second</td>\n",
       "      <td>6.107850e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eval_steps_per_second</td>\n",
       "      <td>7.691400e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>epoch</td>\n",
       "      <td>2.000000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    metric         value\n",
       "0                eval_loss  3.289504e+00\n",
       "1            eval_pearsonr  4.754000e-01\n",
       "2      eval_pearsonr_scipy  4.754218e-01\n",
       "3                eval_pval  1.242750e-16\n",
       "4             eval_runtime  4.421000e-01\n",
       "5  eval_samples_per_second  6.107850e+02\n",
       "6    eval_steps_per_second  7.691400e+01\n",
       "7                    epoch  2.000000e+01"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" output eval metrics from best model \"\"\"\n",
    "\n",
    "trainer.model.cuda()\n",
    "eval_output = trainer.evaluate()\n",
    "eval_result = eval_output[metric_for_best_model]\n",
    "\n",
    "pd.DataFrame({'metric':list(eval_output.keys()), 'value': list(eval_output.values())}, columns=['metric', 'value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6cccea",
   "metadata": {},
   "source": [
    "# Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a108eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 525\n",
      "  Batch size = 8\n",
      "/app/home/alahnala/miniconda3/envs/st/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "\"\"\" make predictions on test dataset \"\"\"\n",
    "\n",
    "p = trainer.predict(test_dataset)\n",
    "preds = p.predictions[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c108d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved predictions to ./predictions/empathy/emotion-stack-eval_pearsonr-47.54_1921-20-4.tsv\n"
     ]
    }
   ],
   "source": [
    "\"\"\" save predictions \"\"\"\n",
    "\n",
    "pred_file = f\"{approach}-{metric_for_best_model}-{round(eval_result * 100, 4)}_{dateTimeObj.hour}{dateTimeObj.minute}-{dateTimeObj.day}-{dateTimeObj.month}.tsv\"\n",
    "pred_path = f'./predictions/{prediction_task}/{pred_file}'\n",
    "os.makedirs(f'./predictions/{prediction_task}/', exist_ok=True)\n",
    "pd.Series(preds).to_csv(pred_path, sep='\\t', header=False, index=False)\n",
    "print(\"saved predictions to\",pred_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aa8f64",
   "metadata": {},
   "source": [
    "# Save the adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f24ff109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.model.save_adapter(f\"./trained_adapters/{adapter_name}\", adapter_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
